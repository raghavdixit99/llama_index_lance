{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/ai21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI21\n",
    "\n",
    "This notebook shows how to use AI21's newest model - Jamba-Instruct. Along with support for the previous model family - Jurassic (J2-Mid and J2-Ultra).\n",
    "\n",
    "By default - jamba-instruct model is used. If you want to use the Jurassic models, you can specify the model name as \"j2-mid\" or \"j2-ultra\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the AI21 instance, you can pass the API key as a parameter or by default, it will be consumed from the environment variable `AI21_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a computer scientist, entrepreneur, and author. He is best known as the co-founder of Y Combinator, a venture capital firm that provides seed funding to early-stage startups. He is also a well-known essayist and writer on various topics such as programming, startups, and technology. He has written several influential essays on these topics, which have been widely read and discussed in the tech community.\n",
      "Paul Graham is a computer scientist, entrepreneur, and essayist known for his work in the field of computer programming and his contributions to the startup ecosystem. He is the co-founder of Viaweb, which was later sold to Yahoo! and became Yahoo! Store. Graham is also recognized for his essays on various topics related to technology, startups, and the nature of innovation, which are widely read and discussed in the tech community. He co-founded Y Combinator, one of the most prominent startup accelerators in the world, which has helped launch over a thousand startups, including notable companies like Airbnb, Dropbox, and Reddit. His insights and writings on entrepreneurship and technology have made him a respected and influential voice in the tech world.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.llms.ai21 import AI21\n",
    "\n",
    "api_key = \"Your-api-key\"\n",
    "os.environ[\"AI21_API_KEY\"] = api_key\n",
    "\n",
    "llm = AI21()\n",
    "\n",
    "# Or\n",
    "llm = AI21(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call `chat` with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.ai21 import AI21\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"hello there\"),\n",
    "    ChatMessage(\n",
    "        role=\"assistant\", content=\"Arrrr, matey! How can I help ye today?\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "\n",
    "resp = AI21(api_key=api_key).chat(\n",
    "    messages, preamble_override=\"You are a pirate with a colorful personality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call `complete` with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ai21 import AI21\n",
    "\n",
    "api_key = \"Your api key\"\n",
    "resp = AI21(api_key=api_key).complete(\"Paul Graham is \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "an American computer scientist, essayist, and venture capitalist. He is best known for his work on Lisp, programming language design, and entrepreneurship. Graham has written several books on these topics, including \" ANSI Common Lisp\" and \" Hackers and Painters.\" He is also the co-founder of Y Combinator, a venture capital firm that invests in early-stage technology companies.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the parameter passed to the model like - `max_tokens`, `temperature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ai21 import AI21\n",
    "\n",
    "llm = AI21(\n",
    "    model=\"jamba-instruct\", api_key=api_key, max_tokens=100, temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Paul Graham is \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "an American computer scientist, essayist, and venture capitalist. He is best known for his work on Lisp, programming language design, and entrepreneurship. Graham has written several books on these topics, including \" ANSI Common Lisp\" and \" Hackers and Painters.\" He is also the co-founder of Y Combinator, a venture capital firm that invests in early-stage technology companies.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set API Key at a per-instance level\n",
    "If desired, you can have separate LLM instances use separate API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ai21 import AI21\n",
    "\n",
    "llm_good = AI21(api_key=api_key)\n",
    "llm_bad = AI21(model=\"j2-mid\", api_key=\"BAD_KEY\")\n",
    "\n",
    "resp = llm_good.complete(\"Paul Graham is \")\n",
    "print(resp)\n",
    "\n",
    "resp = llm_bad.complete(\"Paul Graham is \")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using `stream_chat` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ai21 import AI21\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "llm = AI21(api_key=api_key, model=\"jamba-instruct\")\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n",
    "]\n",
    "resp = llm.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Once upon a time, there was a pirate named Captain Jack. He was a very colorful pirate with a love for adventure and treasure. He sailed the seven seas, always searching for his next big score.\n",
      "\n",
      "One day, he stumbled upon a map that led to a hidden island filled with gold and riches beyond his wildest dreams. He gathered his loyal crew and set sail towards the island.\n",
      "\n",
      "As they approached the island, they were met with treacherous waters and dangerous obstacles. But Captain Jack was determined to find the treasure, and he wouldn't let anything stand in his way.\n",
      "\n",
      "Finally, after days of searching, they found the hidden island. They docked their ship and made their way through the dense jungle, following the map to the treasure.\n",
      "\n",
      "As they approached the treasure, they were met with a group of fierce warriors who guarded the treasure. But Captain Jack and his crew were not afraid. They fought bravely and defeated the warriors, finally reaching the treasure.\n",
      "\n",
      "They opened the treasure chest to find it filled with gold, jewels, and other valuable treasures. They were overjoyed and celebrated their victory.\n",
      "\n",
      "But Captain Jack knew that they couldn't stay on the island forever. They loaded their ship with the treasure and set sail back home.\n",
      "\n",
      "As they sailed away, they were met with a fierce storm that threatened to sink their ship. But Captain Jack was determined to make it back home with the treasure. He fought against the storm with all his might, and eventually, they made it through.\n",
      "\n",
      "Captain Jack and his crew finally made it back to their home port, where they were greeted as heroes. They had returned with a treasure that would make them rich beyond their wildest dreams.\n",
      "\n",
      "And so, Captain Jack and his crew lived happily ever after, sailing the seas and searching for their next big adventure."
     ]
    }
   ],
   "source": [
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of the tokenizer is determined by the name of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ai21 import AI21\n",
    "\n",
    "llm = AI21(api_key=api_key, model=\"jamba-instruct\")\n",
    "\n",
    "tokenizer = llm.tokenizer\n",
    "\n",
    "tokens = tokenizer.encode(\"Hello llama-index!\")\n",
    "\n",
    "decoded = tokenizer.decode(tokens)\n",
    "\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-2x1vjWb5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
